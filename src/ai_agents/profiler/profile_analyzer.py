from __future__ import annotations
from langchain_openai import ChatOpenAI
import langchain
from src.config import Config

langchain.verbose = False
langchain.debug = False
langchain.llm_cache = False


ANALYZE_PROMPT = """
Tu es un expert en analyse de comp√©tences IA. Analyse en profondeur les r√©sultats du quiz pour cr√©er un profil d'apprentissage d√©taill√© et personnalis√©.

DONN√âES UTILISATEUR:
{user_json}

R√âSULTATS DU QUIZ:
{evaluation_json}

üéØ MISSION:
Analyse chaque r√©ponse pour identifier:
1. Les forces et faiblesses sp√©cifiques en IA
2. Les lacunes de connaissances pr√©cises
3. Le style d'apprentissage (conceptuel vs pratique)
4. Les domaines IA √† prioriser
5. Le niveau de maturit√© en IA

üìä ANALYSE D√âTAILL√âE REQUISE:

A. NIVEAU (1-10):
- Calcule le niveau en fonction du score ET de la complexit√© des questions r√©ussies
- Score 0-30%: niveau 1-3 (d√©butant)
- Score 30-50%: niveau 4-5 (interm√©diaire bas)
- Score 50-70%: niveau 6-7 (interm√©diaire)
- Score 70-85%: niveau 8-9 (avanc√©)
- Score 85-100%: niveau 10 (expert)

B. COMP√âTENCES (liste d√©taill√©e):
- Liste UNIQUEMENT les comp√©tences IA d√©montr√©es dans les r√©ponses correctes
- Sois sp√©cifique: pas "IA" mais "Deep Learning", "CNN", "NLP", "Reinforcement Learning", etc.
- Identifie les sous-domaines ma√Ætris√©s
- Maximum 5-7 comp√©tences sp√©cifiques

C. OBJECTIFS (texte d√©taill√©):
- Identifie les lacunes pr√©cises bas√©es sur les erreurs
- Propose un parcours d'apprentissage progressif
- Mentionne les concepts IA √† renforcer
- Sois concret et actionnable

D. MOTIVATION (analyse psychologique):
- D√©duis la motivation du score et du profil utilisateur
- Est-ce orient√© carri√®re, curiosit√© intellectuelle, projet sp√©cifique?
- Adapte le ton (encourageant si score faible, challengeant si score √©lev√©)

E. ENERGIE (1-10):
- Base-toi sur le taux de compl√©tion et la qualit√© des r√©ponses ouvertes
- Questions ouvertes remplies = √©nergie haute
- Questions ouvertes vides = √©nergie basse

F. PR√âF√âRENCES (objet d√©taill√©):
- **themes**: Liste 3-5 th√®mes IA pr√©cis bas√©s sur les r√©ponses correctes/incorrectes
  (ex: ["R√©seaux de neurones", "Computer Vision", "Transfer Learning"])
- **type_de_questions**: Analyse quel type de questions a le mieux r√©ussi
  (ChoixMultiple, VraiOuFaux, QuestionOuverte, ListeOuverte)
- **niveau_cible**: D√©finit le niveau √† atteindre dans les 3 mois
  (debutant, intermediaire, avance, expert)
- **style_apprentissage**: Ajoute ce champ (theorique, pratique, mixte)
- **domaines_a_renforcer**: Liste 2-3 domaines IA o√π l'utilisateur a √©chou√©
- **points_forts**: Liste 2-3 domaines IA o√π l'utilisateur a excell√©

G. RECOMMANDATIONS (nouveau champ):
- Ajoute un champ "recommandations" avec 3-5 actions concr√®tes
- Exemple: "Approfondir les CNN avec un projet pratique", "Revoir les bases du backpropagation"

üö® FORMAT JSON STRICT (AUCUN TEXTE AVANT/APR√àS):
{{
  "niveau": 7,
  "competences": ["Deep Learning", "Computer Vision", "R√©seaux de neurones convolutifs"],
  "objectifs": "Renforcer la compr√©hension des architectures de r√©seaux de neurones r√©currents (RNN, LSTM) et approfondir les concepts de NLP. Focus sur la pratique avec des projets concrets de classification de texte.",
  "motivation": "Forte motivation professionnelle avec un int√©r√™t marqu√© pour les applications pratiques de l'IA. Cherche √† acqu√©rir des comp√©tences imm√©diatement applicables en entreprise.",
  "energie": 7,
  "preferences": {{
    "themes": ["Natural Language Processing", "Transformers", "Sentiment Analysis"],
    "type_de_questions": "ChoixMultiple",
    "niveau_cible": "avance",
    "style_apprentissage": "mixte",
    "domaines_a_renforcer": ["Reinforcement Learning", "GANs"],
    "points_forts": ["Computer Vision", "CNN", "Transfer Learning"]
  }},
  "recommandations": [
    "Suivre un cours sur les Transformers (BERT, GPT) pour renforcer les bases en NLP",
    "Impl√©menter un projet de classification d'images avec PyTorch",
    "Revoir les concepts math√©matiques derri√®re le gradient descent",
    "Explorer les applications du Reinforcement Learning avec des tutoriels pratiques"
  ],
  "analyse_detaillee": {{
    "taux_reussite_par_type": {{
      "ChoixMultiple": "80%",
      "VraiOuFaux": "100%",
      "QuestionOuverte": "50%",
      "ListeOuverte": "75%"
    }},
    "forces": [
      "Excellente compr√©hension des concepts fondamentaux de ML",
      "Ma√Ætrise solide des architectures CNN",
      "Bonne connaissance des frameworks PyTorch/TensorFlow"
    ],
    "faiblesses": [
      "Lacunes sur les concepts avanc√©s de NLP",
      "Besoin de renforcer la th√©orie math√©matique",
      "Manque d'exp√©rience en Reinforcement Learning"
    ]
  }}
}}

IMPORTANT:
- Sois PR√âCIS et PERSONNALIS√â bas√© sur les donn√©es r√©elles
- Ne g√©n√®re PAS de profil g√©n√©rique
- Utilise les informations du quiz pour justifier chaque champ
- Si une question ouverte est vide, note-le dans l'√©nergie
- Si l'utilisateur a tout bon dans un domaine, mets-le dans points_forts

G√âN√àRE LE JSON MAINTENANT:
"""


def _niveau_from_score(score_percentage: float) -> int:
    try:
        pct = max(0.0, min(100.0, float(score_percentage)))
        # Map 0..100 -> 1..10
        bucket = int(pct // 10) + 1
        return max(1, min(10, bucket))
    except Exception:
        return 5


def analyze_profile_with_llm(user_json: str, evaluation_json: str, *, model: str = "granite4:latest", base_url: str = "http://192.168.1.2:11434") -> str:
    """Appelle l'LLM pour g√©n√©rer un profil JSON strict.
    Retourne une cha√Æne JSON (ou texte brut si le mod√®le ne respecte pas strictement le format)."""
    prompt = ANALYZE_PROMPT.format(user_json=user_json, evaluation_json=evaluation_json)

    # Utilisation correcte de ChatOpenAI avec la cl√© API
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        api_key=Config.OPENAI_API_KEY,
        temperature=0.3
    )
    response = llm.invoke(prompt)
    return response.content if hasattr(response, "content") else str(response)
