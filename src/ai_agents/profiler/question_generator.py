from langchain_ollama import ChatOllama
import langchain
from langchain_openai import ChatOpenAI

from src.config import Config

langchain.verbose = False
langchain.debug = False
langchain.llm_cache = False
from src.users.schema import UtilisateurRead

# Prompt optimis√© pour une g√©n√©ration plus rapide
BASE_PROMPT = """
Tu es un g√©n√©rateur de quiz sur l'INTELLIGENCE ARTIFICIELLE uniquement.

üö® R√àGLE ABSOLUE üö®
Tu dois cr√©er 10 questions EXCLUSIVEMENT sur l'Intelligence Artificielle.
INTERDICTION FORMELLE de poser des questions sur :
‚ùå Python (sauf libraries IA : TensorFlow, PyTorch, Keras, scikit-learn)
‚ùå SQL, bases de donn√©es, ETL, Data Engineering
‚ùå R, statistiques g√©n√©rales
‚ùå Pandas, NumPy (sauf dans un contexte IA explicite)
‚ùå D√©veloppement web, DevOps, Cloud

‚úÖ SUJETS AUTORIS√âS (Intelligence Artificielle uniquement) :
- Machine Learning : algorithmes, mod√®les, apprentissage supervis√©/non supervis√©
- Deep Learning : r√©seaux de neurones, CNN, RNN, LSTM, Transformers
- NLP (Natural Language Processing) : traitement du langage naturel
- Computer Vision : reconnaissance d'images, d√©tection d'objets
- Reinforcement Learning : apprentissage par renforcement
- Outils IA : TensorFlow, PyTorch, Keras, scikit-learn, Hugging Face
- Concepts IA : overfitting, underfitting, backpropagation, gradient descent
- Applications IA : chatbots, reconnaissance vocale, syst√®mes de recommandation

PROFIL UTILISATEUR (pour adapter la difficult√© uniquement) :
- Statut: {status}
- Comp√©tences: {competences}
- Objectif: {objectifs_apprentissage}
- Niveau: {niveau_technique}/10

TYPES DE QUESTIONS :
1-2: ChoixMultiple (4 options A/B/C/D)
3-4: VraiOuFaux (A. Vrai / B. Faux)
5-6: QuestionOuverte (pas d'options)
7-8: ListeOuverte (pas d'options)
9-10: ChoixMultiple (4 options A/B/C/D)

FORMAT JSON STRICT (pas de texte avant/apr√®s) :
[
  {{
    "numero": 1,
    "question": "Quelle est la diff√©rence entre apprentissage supervis√© et non supervis√© ?",
    "type": "ChoixMultiple",
    "options": ["A. L'un utilise des labels", "B. L'un est plus rapide", "C. Pas de diff√©rence", "D. L'un utilise moins de donn√©es"],
    "correction": "A - L'apprentissage supervis√© utilise des donn√©es √©tiquet√©es."
  }}
]

EXEMPLES VALIDES :
‚úÖ "Qu'est-ce qu'un neurone artificiel ?"
‚úÖ "Comment fonctionne la r√©tropropagation ?"
‚úÖ "Citez 3 architectures de r√©seaux de neurones"
‚úÖ "Quelle est la fonction d'activation la plus utilis√©e ?"

EXEMPLES INVALIDES :
‚ùå "Qu'est-ce qu'un DataFrame en Pandas ?"
‚ùå "Comment faire une jointure SQL ?"
‚ùå "Qu'est-ce qu'un ETL ?"

G√âN√àRE MAINTENANT 10 QUESTIONS IA (JSON uniquement) :
"""

def generate_profile_question(user: UtilisateurRead) -> str:
    """G√©n√®re 10 questions personnalis√©es rapidement."""
    prompt = BASE_PROMPT.format(
        status=user.status,
        competences=", ".join(user.competences or ["Aucune"]),
        objectifs_apprentissage=user.objectifs_apprentissage or "Non sp√©cifi√©",
        niveau_technique=user.niveau_technique or 5
    )

    # Configuration LLM optimis√©e pour la vitesse
    llm = ChatOpenAI(
        model="gpt-4o-mini",  # Corrig√© : gpt-5-mini n'existe pas
        api_key=Config.OPENAI_API_KEY,
        temperature=0.7
    )
    question = llm.invoke(prompt)
    return question.content
